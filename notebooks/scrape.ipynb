{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A very simple and basic web scraping script. Feel free to\n",
    "use this as a source of inspiration, but, make sure to attribute\n",
    "it if you do so.\n",
    "\n",
    "This is by no means production code.\n",
    "\"\"\"\n",
    "# built-in imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "from jsonmerge import merge\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# user packages\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "\n",
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 11) # update this to your liking\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Web Scraping</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes = pd.read_csv(\"../data/curated/unique_postcodes.csv\", header=None).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Progress tracker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports & functions for progress tracking, can be removed for final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "import timeit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_tracker(start, stop, curr_progress):\n",
    "    if (curr_progress*100) < 5:\n",
    "        expected_time = \"Calculating...\"\n",
    "    else:\n",
    "        time_perc = timeit.default_timer()\n",
    "        expected_time = np.round(((time_perc-start) / curr_progress)/60, 2)\n",
    "\n",
    "    print(\"Current progress:\", np.round(curr_progress*100, 2), \"%\")\n",
    "    print(\"current run time:\", np.round((stop-start)/60, 2), \"minutes\")\n",
    "    print(\"Expected run time:\", expected_time, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selenium (optional running)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "driver_location = \"/usr/bin/chromedriver\"\n",
    "binary_location = \"/usr/bin/google-chrome\"\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = binary_location\n",
    "\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "s=Service(driver_location)\n",
    "\n",
    "driver = webdriver.Chrome(service=s, options=options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**URL Scraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: 99.86 %\n",
      "current run time: 56.52 minutes\n",
      "Expected run time: 56.6 minutes\n"
     ]
    }
   ],
   "source": [
    "# begin code\n",
    "url_dict = defaultdict(dict)\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "start = timeit.default_timer() # for progress tracking\n",
    "\n",
    "# index & enumerate are for progress tracking, can be removed for final submission\n",
    "for index, postcode in enumerate(postcodes):\n",
    "    clear_output(wait=True) # for progress tracking\n",
    "\n",
    "    url_links = []\n",
    "    \n",
    "    # generate list of urls to visit\n",
    "    for page in N_PAGES:\n",
    "        # need to decide regions to analyse         \n",
    "        url = BASE_URL + f\"/rent/?postcode={postcode}&page={page}\" # a single page\n",
    "        bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\") # makes bs object\n",
    "        time.sleep(random.randint(0, 3))\n",
    "\n",
    "        # find the unordered list (ul) elements which are the results, then\n",
    "        # find all href (a) tags that are from the base_url website.\n",
    "        index_links = bs_object.find(\"ul\", {\"data-testid\": \"results\"}) \n",
    "\n",
    "        # if there are no links, break\n",
    "        if (index_links == None):\n",
    "            break \n",
    "\n",
    "        index_links = index_links.findAll(\"a\",href=re.compile(f\"{BASE_URL}/*\")) # complies RE string into RE expression\n",
    "            \n",
    "        for link in index_links:\n",
    "            # if its a property address, add it to the list\n",
    "            if 'address' in link['class']:\n",
    "                url_links.append(link['href'])\n",
    "\n",
    "    url_dict[postcode] = url_links\n",
    "\n",
    "    # for progress tracking\n",
    "    curr_progress = index/len(postcodes)\n",
    "    stop = timeit.default_timer()\n",
    "    progress_tracker(start, stop, curr_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store url_dict for future use\n",
    "json.dump(url_dict, open(\"../data/curated/url_dict.json\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously run url_dict\n",
    "# only run if URL scraping has not been executed\n",
    "url_dict = json.load(open( \"../data/curated/url_dict.json\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_jade = postcodes[0:200]\n",
    "postcodes_kelman = postcodes[200:716]\n",
    "\n",
    "output_jade = \"../data/curated/property_metadata_0-199.json\"\n",
    "output_kelman = \"../data/curated/property_metadata_200-715.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: 99.5 %\n",
      "current run time: 183.57 minutes\n",
      "Expected run time: 184.49 minutes\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer() # for progress tracking\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "for index, postcode in enumerate(postcodes_jade):\n",
    "    clear_output(wait=True) # for progress tracking\n",
    "    \n",
    "    url_links = url_dict.get(str(postcode))\n",
    "\n",
    "    for property_url in url_links:\n",
    "        bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # looks for the header class to get property name\n",
    "        name = bs_object.find(\"h1\", {\"class\": \"css-164r41r\"})\n",
    "        if name == None: \n",
    "            break \n",
    "        else: \n",
    "            property_metadata[property_url]['Name'] = name.text\n",
    "\n",
    "\n",
    "        # regex to find the cost in the summary title \n",
    "        cost_finder = re.compile(r'[0-9]+.?[0-9]+') # this regex search assumes that the first numeric value is the cost per week \n",
    "        # looks for the div containing a summary title for cost\n",
    "        cost_text = bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "            .text\n",
    "\n",
    "        # extracts the cost from the summary title and adds to dictionary. \n",
    "        # if there is no cost written in the summary title, it is replaced by 0 \n",
    "        cost = cost_finder.search(cost_text)\n",
    "        if cost == None: \n",
    "            property_metadata[property_url]['Cost'] = 0\n",
    "        else:\n",
    "            property_metadata[property_url]['Cost'] = cost.group()\n",
    "            \n",
    "        # extract coordinates from the hyperlink provided\n",
    "        # finds latitude and longitude from integrated Google Map\n",
    "        property_metadata[property_url]['Coordinates'] = [\n",
    "            float(coord) for coord in re.findall(\n",
    "                r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "                bs_object \\\n",
    "                    .find(\n",
    "                        \"a\",\n",
    "                        {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                    ) \\\n",
    "                    .attrs['href']\n",
    "            )[0].split(',')\n",
    "        ]\n",
    "        \n",
    "        # extracts # of bedrooms, # of baths and # of parking spots \n",
    "        rooms_info = bs_object.find(\"div\", {\"data-testid\": \"property-features\"}).findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "        for i in range(0, min(3, len(rooms_info))):\n",
    "            attr_desc = str(rooms_info[i].text).split(' ')\n",
    "\n",
    "            property_metadata[property_url][attr_desc[1]] = attr_desc[0]\n",
    "\n",
    "        # extracts property type from the site \n",
    "        property_metadata[property_url]['Property_Type'] = bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}).find(\"span\", {\"class\" : \"css-in3yi3\"}).text\n",
    "\n",
    "        # extracts desciption from the site \n",
    "        # will significantly increase run-time\n",
    "        '''\n",
    "        driver.get(property_url)\n",
    "        read_more_button = driver.find_element(by=By.CSS_SELECTOR , value='[data-testid=\"listing-details__description-button\"]')\n",
    "        read_more_button.click()\n",
    "        property_metadata[property_url]['Desc'] = driver.find_element(by=By.CSS_SELECTOR, value='[data-testid=\"listing-details__description\"]').text\n",
    "        '''\n",
    "\n",
    "        # extract real estate agency\n",
    "        agency = bs_object.find(\"a\", {\"data-testid\" : \"listing-details__agent-details-agent-company-name\"})\n",
    "        if agency == None:\n",
    "            property_metadata[property_url]['Agency'] = \"-\"\n",
    "        else:\n",
    "            property_metadata[property_url]['Agency'] = agency.text\n",
    "\n",
    "        # add postcode\n",
    "        property_metadata[property_url]['Postcode'] = postcode\n",
    "\n",
    "    # for progress tracking\n",
    "    curr_progress = index/len(postcodes_jade)\n",
    "    stop = timeit.default_timer()\n",
    "    progress_tracker(start, stop, curr_progress)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store property metadata for future use\n",
    "json.dump(property_metadata, open(output_jade, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old code for one person to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.domain.com.au', port=443): Max retries exceeded with url: /10-finch-street-norlane-vic-3214-16054497 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb79386e280>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:918\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    917\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 918\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    919\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7fb79386e280>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    440\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    441\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    442\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    443\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    444\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    445\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    449\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    450\u001b[0m     )\n\u001b[1;32m    452\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.domain.com.au', port=443): Max retries exceeded with url: /10-finch-street-norlane-vic-3214-16054497 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb79386e280>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jade/Documents/GitHub/generic-real-estate-consulting-project-group-42/notebooks/scrape.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Jade/Documents/GitHub/generic-real-estate-consulting-project-group-42/notebooks/scrape.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m url_links \u001b[39m=\u001b[39m url_dict\u001b[39m.\u001b[39mget(postcode)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Jade/Documents/GitHub/generic-real-estate-consulting-project-group-42/notebooks/scrape.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m property_url \u001b[39min\u001b[39;00m url_links:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Jade/Documents/GitHub/generic-real-estate-consulting-project-group-42/notebooks/scrape.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     bs_object \u001b[39m=\u001b[39m BeautifulSoup(requests\u001b[39m.\u001b[39;49mget(property_url, headers\u001b[39m=\u001b[39;49mheaders)\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Jade/Documents/GitHub/generic-real-estate-consulting-project-group-42/notebooks/scrape.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Jade/Documents/GitHub/generic-real-estate-consulting-project-group-42/notebooks/scrape.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# looks for the header class to get property name\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m'\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py:60\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:533\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    529\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    530\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    531\u001b[0m }\n\u001b[1;32m    532\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 533\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    535\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:646\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    645\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    648\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    649\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py:516\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    513\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    518\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.domain.com.au', port=443): Max retries exceeded with url: /10-finch-street-norlane-vic-3214-16054497 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb79386e280>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer() # for progress tracking\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "\n",
    "# for each url, scrape features\n",
    "# index & enumerate are for progress tracking, can be removed for final submission\n",
    "for index, postcode in enumerate(url_dict):\n",
    "    clear_output(wait=True) # for progress tracking\n",
    "\n",
    "    url_links = url_dict.get(postcode)\n",
    "\n",
    "    for property_url in url_links:\n",
    "        bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # looks for the header class to get property name\n",
    "        name = bs_object.find(\"h1\", {\"class\": \"css-164r41r\"})\n",
    "        if name == None: \n",
    "            break \n",
    "        else: \n",
    "            property_metadata[property_url]['Name'] = name.text\n",
    "\n",
    "\n",
    "        # regex to find the cost in the summary title \n",
    "        cost_finder = re.compile(r'[0-9]+.?[0-9]+') # this regex search assumes that the first numeric value is the cost per week \n",
    "        # looks for the div containing a summary title for cost\n",
    "        cost_text = bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "            .text\n",
    "\n",
    "        # extracts the cost from the summary title and adds to dictionary. \n",
    "        # if there is no cost written in the summary title, it is replaced by 0 \n",
    "        cost = cost_finder.search(cost_text)\n",
    "        if cost == None: \n",
    "            property_metadata[property_url]['Cost'] = 0\n",
    "        else:\n",
    "            property_metadata[property_url]['Cost'] = cost.group()\n",
    "            \n",
    "        # extract coordinates from the hyperlink provided\n",
    "        # finds latitude and longitude from integrated Google Map\n",
    "        property_metadata[property_url]['Coordinates'] = [\n",
    "            float(coord) for coord in re.findall(\n",
    "                r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "                bs_object \\\n",
    "                    .find(\n",
    "                        \"a\",\n",
    "                        {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                    ) \\\n",
    "                    .attrs['href']\n",
    "            )[0].split(',')\n",
    "        ]\n",
    "        \n",
    "        # extracts # of bedrooms, # of baths and # of parking spots \n",
    "        rooms_info = bs_object.find(\"div\", {\"data-testid\": \"property-features\"}).findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "        for i in range(0, min(3, len(rooms_info))):\n",
    "            attr_desc = str(rooms_info[i].text).split(' ')\n",
    "\n",
    "            property_metadata[property_url][attr_desc[1]] = attr_desc[0]\n",
    "\n",
    "        # extracts property type from the site \n",
    "        property_metadata[property_url]['Property_Type'] = bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}).find(\"span\", {\"class\" : \"css-in3yi3\"}).text\n",
    "\n",
    "        # extracts desciption from the site \n",
    "        # will significantly increase run-time\n",
    "        '''\n",
    "        driver.get(property_url)\n",
    "        read_more_button = driver.find_element(by=By.CSS_SELECTOR , value='[data-testid=\"listing-details__description-button\"]')\n",
    "        read_more_button.click()\n",
    "        property_metadata[property_url]['Desc'] = driver.find_element(by=By.CSS_SELECTOR, value='[data-testid=\"listing-details__description\"]').text\n",
    "        '''\n",
    "\n",
    "        # extract real estate agency\n",
    "        agency = bs_object.find(\"a\", {\"data-testid\" : \"listing-details__agent-details-agent-company-name\"})\n",
    "        if agency == None:\n",
    "            property_metadata[property_url]['Agency'] = \"-\"\n",
    "        else:\n",
    "            property_metadata[property_url]['Agency'] = agency.text\n",
    "\n",
    "        # add postcode\n",
    "        property_metadata[property_url]['Postcode'] = postcode\n",
    "\n",
    "    # for progress tracking\n",
    "    curr_progress = index/len(url_dict)\n",
    "    stop = timeit.default_timer()\n",
    "    progress_tracker(start, stop, curr_progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously run property_metadata\n",
    "# only run if URL scraping has not been executed\n",
    "base = json.load(open(output_jade))\n",
    "head = json.load(open(output_kelman))\n",
    "\n",
    "combined = merge(base, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for url in url_dict.values():\n",
    "    for url_link in url:\n",
    "        info = combined.get(url_link)\n",
    "        if info == None:\n",
    "            break\n",
    "        else:\n",
    "            data.append(list(info.values()))        \n",
    "        \n",
    "      \n",
    "property_df = pd.DataFrame(data)\n",
    "\n",
    "property_df = property_df.iloc[:,]\n",
    "property_df.columns = ['Name', 'Cost', 'Coordinates', 'Bed', 'Bath', 'Parking', 'Property_Type', 'Agency', 'Postcode']\n",
    "\n",
    "property_df.to_csv('../data/raw/property_data.csv')  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Bed</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Parking</th>\n",
       "      <th>Property_Type</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5408/500 Elizabeth Street Melbourne VIC 3000</td>\n",
       "      <td>440</td>\n",
       "      <td>[-37.8072443, 144.9602814]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>−</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>BRADY residential</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502/118 Russell Street Melbourne VIC 3000</td>\n",
       "      <td>620</td>\n",
       "      <td>[-37.8135864, 144.9687232]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>−</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>Dingle Partners</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202A/441 Lonsdale Street Melbourne VIC 3000</td>\n",
       "      <td>300</td>\n",
       "      <td>[-37.8134292, 144.9594445]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>−</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>Biggin &amp; Scott Stonnington</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57/243 Collins Street Melbourne VIC 3000</td>\n",
       "      <td>400</td>\n",
       "      <td>[-37.8159969, 144.9657956]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>−</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>Harcourts Melbourne City</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2311/601 Little Lonsdale Street Melbourne VIC ...</td>\n",
       "      <td>625</td>\n",
       "      <td>[-37.8137564, 144.9537143]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Apartment / Unit / Flat</td>\n",
       "      <td>Harcourts Melbourne City</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13642</th>\n",
       "      <td>Inverloch VIC 3996</td>\n",
       "      <td>475</td>\n",
       "      <td>[-38.6314613, 145.7293638]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "      <td>Southcoast First National Inverloch</td>\n",
       "      <td>3996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13643</th>\n",
       "      <td>25A Veronica Street Inverloch VIC 3996</td>\n",
       "      <td>400</td>\n",
       "      <td>[-38.6428993, 145.7101579]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "      <td>Stockdale &amp; Leggo Inverloch</td>\n",
       "      <td>3996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>16B Sandy Mount Avenue Inverloch VIC 3996</td>\n",
       "      <td>400.00</td>\n",
       "      <td>[-38.6340011, 145.725239]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "      <td>Alex Scott &amp; Staff Inverloch</td>\n",
       "      <td>3996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13645</th>\n",
       "      <td>64 Dixon Street Inverloch VIC 3996</td>\n",
       "      <td>0</td>\n",
       "      <td>[-38.6313719, 145.717275]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>−</td>\n",
       "      <td>House</td>\n",
       "      <td>Stockdale &amp; Leggo Inverloch</td>\n",
       "      <td>3996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13646</th>\n",
       "      <td>28 Beachcomber Drive Inverloch VIC 3996</td>\n",
       "      <td>550</td>\n",
       "      <td>[-38.6412502, 145.7031282]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>−</td>\n",
       "      <td>House</td>\n",
       "      <td>Southcoast First National Inverloch</td>\n",
       "      <td>3996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13647 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Name    Cost  \\\n",
       "0           5408/500 Elizabeth Street Melbourne VIC 3000     440   \n",
       "1              502/118 Russell Street Melbourne VIC 3000     620   \n",
       "2            202A/441 Lonsdale Street Melbourne VIC 3000     300   \n",
       "3               57/243 Collins Street Melbourne VIC 3000     400   \n",
       "4      2311/601 Little Lonsdale Street Melbourne VIC ...     625   \n",
       "...                                                  ...     ...   \n",
       "13642                                 Inverloch VIC 3996     475   \n",
       "13643             25A Veronica Street Inverloch VIC 3996     400   \n",
       "13644          16B Sandy Mount Avenue Inverloch VIC 3996  400.00   \n",
       "13645                 64 Dixon Street Inverloch VIC 3996       0   \n",
       "13646            28 Beachcomber Drive Inverloch VIC 3996     550   \n",
       "\n",
       "                      Coordinates Bed Bath Parking            Property_Type  \\\n",
       "0      [-37.8072443, 144.9602814]   1    1       −  Apartment / Unit / Flat   \n",
       "1      [-37.8135864, 144.9687232]   1    1       −  Apartment / Unit / Flat   \n",
       "2      [-37.8134292, 144.9594445]   1    1       −  Apartment / Unit / Flat   \n",
       "3      [-37.8159969, 144.9657956]   1    1       −  Apartment / Unit / Flat   \n",
       "4      [-37.8137564, 144.9537143]   2    2       1  Apartment / Unit / Flat   \n",
       "...                           ...  ..  ...     ...                      ...   \n",
       "13642  [-38.6314613, 145.7293638]   3    2       1                    House   \n",
       "13643  [-38.6428993, 145.7101579]   3    1       1                    House   \n",
       "13644   [-38.6340011, 145.725239]   2    1       1                    House   \n",
       "13645   [-38.6313719, 145.717275]   1    1       −                    House   \n",
       "13646  [-38.6412502, 145.7031282]   4    2       −                    House   \n",
       "\n",
       "                                    Agency  Postcode  \n",
       "0                        BRADY residential    3000.0  \n",
       "1                          Dingle Partners    3000.0  \n",
       "2               Biggin & Scott Stonnington    3000.0  \n",
       "3                 Harcourts Melbourne City    3000.0  \n",
       "4                 Harcourts Melbourne City    3000.0  \n",
       "...                                    ...       ...  \n",
       "13642  Southcoast First National Inverloch    3996.0  \n",
       "13643          Stockdale & Leggo Inverloch    3996.0  \n",
       "13644         Alex Scott & Staff Inverloch    3996.0  \n",
       "13645          Stockdale & Leggo Inverloch    3996.0  \n",
       "13646  Southcoast First National Inverloch    3996.0  \n",
       "\n",
       "[13647 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
